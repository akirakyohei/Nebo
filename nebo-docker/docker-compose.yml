version: "0.1"
volumes:
  kong_data: {}
  kong_prefix_vol:
    driver_opts:
      type: tmpfs
      device: tmpfs
  kong_tmp_vol:
    driver_opts:
      type: tmpfs
      device: tmpfs
  redis_data:
    driver: local
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.2
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_SERVERS: zookeeper:2888:3888
  kafka:
    image: confluentinc/cp-kafka:7.6.1
    hostname: kafka
    container_name: kafka
    ports:
      - "9092:9092"
      - "9101:9101"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:29093"
      KAFKA_LISTENERS: "PLAINTEXT://kafka:29092,CONTROLLER://kafka:29093,PLAINTEXT_HOST://0.0.0.0:9092"
      KAFKA_INTER_BROKER_LISTENER_NAME: "PLAINTEXT"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      KAFKA_LOG_DIRS: "/tmp/kraft-combined-logs"
      # Replace CLUSTER_ID with a unique base64 UUID using "bin/kafka-storage.sh random-uuid"
      # See https://docs.confluent.io/kafka/operations-tools/kafka-tools.html#kafka-storage-sh
      CLUSTER_ID: "MkU3OEVBNTcwNTJENDM2Qk"
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
    depends_on:
      - zookeeper
  # kafka:
  #   image: confluentinc/cp-kafka:7.3.2
  #   hostname: kafka
  #   container_name: kafka
  #   ports:
  #     - "9092:9092"
  #     - "29092:29092"
  #   environment:
  #     KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092"
  #     KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
  #     KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
  #   depends_on:
  #     - zookeeper
  kafka-connect:
    image: debezium/connect:1.9
    hostname: kafka-connect
    container_name: kafka-connect
    ports:
      - "8083:8083"
    environment:
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: kafka-connect-configs
      OFFSET_STORAGE_TOPIC: kafka-connect-offsets
      STATUS_STORAGE_TOPIC: kafka-connect-statuses
      BOOTSTRAP_SERVERS: kafka:29092
      CONNECT_TOPIC_CREATION_ENABLE: true
      CONNECT_TOPIC_CREATION_DEFAULT_REPLICATION_FACTOR: "3"
      CONNECT_TOPIC_CREATION_DEFAULT_PARTITIONS: "10"
    restart: on-failure
    depends_on:
      - zookeeper
      - kafka
      - mariadb
  mariadb:
    image: mariadb:lts-jammy
    hostname: mariadb
    container_name: mariadb
    ports:
      - "3306:3306"
    environment:
      MARIADB_ROOT_PASSWORD: "ajdhjewjhredbdbbd"
    command:
      - --log-bin
      - --binlog-format=ROW
  schema-registry:
    image: confluentinc/cp-schema-registry:5.4.0
    ports:
      - "8081:8081"
    hostname: schema-registry
    container_name: schema-registry
    depends_on:
      - zookeeper
      - kafka
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: "zookeeper:2181"
    restart: on-failure
  rest-proxy:
    image: confluentinc/cp-kafka-rest:5.4.0
    ports:
      - "8082:8082"
    hostname: rest-proxy
    container_name: rest-proxy
    depends_on:
      - zookeeper
      - kafka
      - schema-registry
    environment:
      KAFKA_REST_HOST_NAME: rest-proxy
      KAFKA_REST_BOOTSTRAP_SERVERS: kafka:9092
      KAFKA_REST_LISTENERS: "http://rest-proxy:8082"
      KAFKA_REST_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
    restart: on-failure
  # kafka-connect-ui:
  #   image: landoop/kafka-connect-ui:0.9.7
  #   hostname: kafka-connect-ui
  #   container_name: kafka-topics-ui
  #   # kafka-connect-ui binds to port 8000, but we are going to expose it on our local
  #   # machine on port 8002.
  #   ports:
  #     - "8002:8002"
  #   environment:
  #     # Required. Instructs the UI where it can find Kafka Connect.
  #     CONNECT_URL: http://kafka-connect:8083;dev cluster
  #     # This instructs the docker image to use Caddy to proxy traffic to kafka-connect-ui.
  #     PROXY: "true"
  #   # kafka-connect-ui relies upon Kafka Connect.
  #   # This will instruct docker to wait until those services are up
  #   # before attempting to start kafka-connect-ui.
  #   depends_on:
  #     - kafka-connect
  debezium-ui:
    image: debezium/debezium-ui:1.9
    container_name: debezium-ui
    hostname: debezium-ui
    depends_on:
      - kafka-connect
      # condition: service_healthy
    ports:
      - "8080:8080"
    environment:
      KAFKA_CONNECT_URIS: http://kafka-connect:8083
    restart: on-failure
  rabbitmq:
    image: rabbitmq:latest
    container_name: rabbitmq
    hostname: rabbitmq
    ports:
      - "15672:15672"
    environment:
      - RABBITMQ_ERLANG_COOKIE=cluster_cookie
      - RABBITMQ_DEFAULT_USER=admin
      - RABBITMQ_DEFAULT_PASS=admin
  redis:
    image: docker.io/bitnami/redis:7.2
    container_name: redis
    environment:
      # ALLOW_EMPTY_PASSWORD is recommended only for development.
      - ALLOW_EMPTY_PASSWORD=yes
      - REDIS_DISABLE_COMMANDS=FLUSHDB,FLUSHALL
    ports:
      - "6379:6379"
    volumes:
      - "redis_data:/bitnami/redis/data"

  minio:
    image: minio/minio
    container_name: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - ./storage:/data
    environment:
      MINIO_ROOT_USER: admin
      MINIO_ROOT_PASSWORD: abhcsdhjjdsdjjska
    command: server --console-address ":9001" /data

  kong-migrations:
    image: "${KONG_DOCKER_TAG:-kong:latest}"
    container_name: kong-migrations
    command: kong migrations bootstrap
    depends_on:
      - postgresdb
    environment:
      KONG_DATABASE: postgres
      KONG_PG_DATABASE: ${KONG_PG_DATABASE:-kong}
      KONG_PG_HOST: postgresdb
      KONG_PG_USER: ${KONG_PG_USER:-kong}
      KONG_PG_PASSWORD_FILE: /run/secrets/kong_postgres_password
    secrets:
      - kong_postgres_password
    restart: on-failure
    deploy:
      restart_policy:
        condition: on-failure
  kong-migrations-up:
    image: "${KONG_DOCKER_TAG:-kong:latest}"
    container_name: kong-migrations-up
    command: kong migrations up && kong migrations finish
    depends_on:
      - postgresdb
    environment:
      KONG_DATABASE: postgres
      KONG_PG_DATABASE: ${KONG_PG_DATABASE:-kong}
      KONG_PG_HOST: postgresdb
      KONG_PG_USER: ${KONG_PG_USER:-kong}
      KONG_PG_PASSWORD_FILE: /run/secrets/kong_postgres_password
    secrets:
      - kong_postgres_password
    restart: on-failure
    deploy:
      restart_policy:
        condition: on-failure
  kong:
    image: "${KONG_DOCKER_TAG:-kong:latest}"
    user: "${KONG_USER:-kong}"
    hostname: kong
    container_name: kong
    depends_on:
      - postgresdb
    environment:
      KONG_ADMIN_ACCESS_LOG: /dev/stdout
      KONG_ADMIN_ERROR_LOG: /dev/stderr
      KONG_PROXY_LISTEN: "${KONG_PROXY_LISTEN:-0.0.0.0:8000}"
      KONG_ADMIN_LISTEN: "${KONG_ADMIN_LISTEN:-0.0.0.0:8001}"
      KONG_CASSANDRA_CONTACT_POINTS: postgresdb
      KONG_DATABASE: postgres
      KONG_PG_DATABASE: ${KONG_PG_DATABASE:-kong}
      KONG_PG_HOST: postgresdb
      KONG_PG_USER: ${KONG_PG_USER:-kong}
      KONG_PROXY_ACCESS_LOG: /dev/stdout
      KONG_PROXY_ERROR_LOG: /dev/stderr
      KONG_PG_PASSWORD_FILE: /run/secrets/kong_postgres_password
      KONG_PREFIX: ${KONG_PREFIX:-/var/run/kong}
    secrets:
      - kong_postgres_password
    ports:
      - "${KONG_INBOUND_PROXY_LISTEN:-0.0.0.0}:8000:8000/tcp"
      - "${KONG_INBOUND_SSL_PROXY_LISTEN:-0.0.0.0}:8443:8443/tcp"
      - "127.0.0.1:8001:8001/tcp"
      - "127.0.0.1:8444:8444/tcp"
    healthcheck:
      test: ["CMD", "kong", "health"]
      interval: 10s
      timeout: 10s
      retries: 10
    restart: on-failure:5
    read_only: true
    volumes:
      - kong_prefix_vol:${KONG_PREFIX:-/var/run/kong}
      - kong_tmp_vol:/tmp
    deploy:
      restart_policy:
        delay: 50s
        condition: on-failure
        max_attempts: 5
        window: 10s
      resources:
        limits:
          cpus: "${KONG_CPU_LIMIT:-2}"
          memory: ${KONG_MEMORY_LIMIT:-2g}
    security_opt:
      - no-new-privileges
  postgresdb:
    image: postgres:9.5
    container_name: postgresdb
    environment:
      POSTGRES_DB: ${KONG_PG_DATABASE:-kong}
      POSTGRES_USER: ${KONG_PG_USER:-kong}
      POSTGRES_PASSWORD_FILE: /run/secrets/kong_postgres_password
    secrets:
      - kong_postgres_password
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "${KONG_PG_USER:-kong}"]
      interval: 30s
      timeout: 30s
      retries: 3
    restart: on-failure
    deploy:
      restart_policy:
        condition: on-failure
    stdin_open: true
    tty: true
    volumes:
      - kong_data:/var/lib/postgresql/data
  konga-prepare:
    image: pantsel/konga
    container_name: konga-prepare
    command: "-c prepare -a postgres -u postgresql://kong:kong@db:5432/konga"
    restart: on-failure
    links:
      - postgresdb:postgresdb
    depends_on:
      - postgresdb
  konga:
    image: pantsel/konga
    container_name: konga
    restart: on-failure
    links:
      - postgresdb:postgresdb
    depends_on:
      - postgresdb
      - konga-prepare
    env_file:
      - ./konga/.konga-docker-env
    ports:
      - "1337:1337"
secrets:
  kong_postgres_password:
    file: ./konga/POSTGRES_PASSWORD
